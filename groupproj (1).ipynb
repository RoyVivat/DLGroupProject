{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q  datasets peft accelerate bitsandbytes\n",
        "!pip install evaluate rouge_score nltk\n",
        "import transformers, sys\n",
        "print(transformers.__version__)\n",
        "print(transformers.__file__)"
      ],
      "metadata": {
        "id": "gQc1kzSXc86j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mm91LigzPhpS"
      },
      "outputs": [],
      "source": [
        "# from __future__ import annotations\n",
        "import time, nltk, numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments,\n",
        "    TrainerCallback,\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "TRAIN_FILE   = \"train_data_clean.csv\"\n",
        "TEST_FILE    = \"test_data_clean.csv\"\n",
        "VAL_FRAC     = 0.1\n",
        "MAX_SRC_LEN  = 1024\n",
        "MAX_TGT_LEN  = 256\n",
        "BATCH_SIZE   = 6\n",
        "LR           = 2e-5\n",
        "EPOCHS       = 3\n",
        "LOG_STEPS    = 10\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "all_data = load_dataset(\"csv\", data_files={\"train\": TRAIN_FILE, \"test\": TEST_FILE})\n",
        "train_ds, val_ds = all_data[\"train\"].train_test_split(test_size=VAL_FRAC, seed=42).values()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\", use_fast=True)\n",
        "\n",
        "def preprocess(batch):\n",
        "    tok_inp = tokenizer(batch[\"text\"], max_length=MAX_SRC_LEN, truncation=True)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        lbls = tokenizer(batch[\"summary\"], max_length=MAX_TGT_LEN, truncation=True)\n",
        "    tok_inp[\"labels\"] = lbls[\"input_ids\"]\n",
        "    return tok_inp\n",
        "\n",
        "cols = train_ds.column_names\n",
        "train_tok = train_ds.map(preprocess, batched=True, remove_columns=cols, desc=\"Tokenise train\")\n",
        "val_tok = val_ds.map(preprocess,   batched=True, remove_columns=cols, desc=\"Tokenise val\")\n",
        "\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
        "collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=-100)\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def _sent_split(txts):\n",
        "    return [\"\".join(nltk.sent_tokenize(t.strip())) for t in txts]\n",
        "\n",
        "def _decode(seqs):\n",
        "    return [tokenizer.decode([int(x) for x in seq if int(x) >= 0], skip_special_tokens=True) for seq in seqs]\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    y_pred, y_true = pred\n",
        "    if isinstance(y_pred, tuple):\n",
        "        y_pred = y_pred[0]\n",
        "    preds = _sent_split(_decode(y_pred))\n",
        "    refs  = _sent_split(_decode(np.where(y_true != -100, y_true, tokenizer.pad_token_id)))\n",
        "    return {k: round(v * 100, 4) for k, v in rouge.compute(predictions=preds, references=refs, use_stemmer=True).items()}\n",
        "\n",
        "train_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_strategy=\"steps\", logging_steps=LOG_STEPS,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"no\",\n",
        "    learning_rate=LR,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=MAX_TGT_LEN,\n",
        "    save_total_limit=3,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "    # trainer.train()\n",
        "\n",
        "    # final_path = \"./results/final_model\"\n",
        "    # trainer.save_model(final_path)\n",
        "    # print(f\"Model saved to {final_path}\")\n",
        "\n",
        "    # print(\"Validation:\")\n",
        "    # val_metrics = trainer.evaluate()\n",
        "    # print(val_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "print(\"Running single validation evaluationâ€¦\")\n",
        "val_metrics = trainer.evaluate()\n",
        "print(\"Validation ROUGE:\", val_metrics)"
      ],
      "metadata": {
        "id": "qXQMjhwtdC6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_state()\n",
        "\n",
        "import json, os\n",
        "json_path = \"./trainer_state_post.json\"\n",
        "trainer.state.save_to_json(json_path)\n",
        "print(\"state written to\", os.path.abspath(json_path))"
      ],
      "metadata": {
        "id": "5sq5f_h_V3cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with open(\"/content/trainer_state_post.json\") as f:\n",
        "    history = json.load(f)[\"log_history\"]\n",
        "\n",
        "train_steps, train_losses, eval_steps, eval_losses = [], [], [], []\n",
        "for x in history:\n",
        "    if \"loss\" in x: train_steps.append(x[\"step\"]); train_losses.append(x[\"loss\"])\n",
        "    if \"eval_loss\" in x: eval_steps.append(x[\"step\"]); eval_losses.append(x[\"eval_loss\"])\n",
        "\n",
        "plt.plot(train_steps, train_losses, label=\"Train Loss\", marker=\"o\")\n",
        "plt.plot(eval_steps, eval_losses, label=\"Eval Loss\", marker=\"x\")\n",
        "plt.xlabel(\"Step\"); plt.ylabel(\"Loss\"); plt.legend(); plt.grid(); plt.tight_layout()\n",
        "plt.savefig(\"/content/loss_plot.png\")"
      ],
      "metadata": {
        "id": "TP_uu81l4PxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./my_final_model\")"
      ],
      "metadata": {
        "id": "MvdAhBEWcWBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content.zip /content/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content.zip\")"
      ],
      "metadata": {
        "id": "0lPohU1-zKGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/sample_data/"
      ],
      "metadata": {
        "id": "RBPdb1PA1GpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"\\nGenerating one example from validation set:\")\n",
        "sample = val_ds[0][\"text\"]\n",
        "target = val_ds[0][\"summary\"]\n",
        "\n",
        "inputs = tokenizer(sample, return_tensors=\"pt\", truncation=True, max_length=MAX_SRC_LEN).to(model.device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_length=MAX_TGT_LEN)\n",
        "prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"SOURCE:\\n\", sample[:500], \"...\\n\")\n",
        "print(\"REFERENCE SUMMARY:\\n\", target, \"\\n\")\n",
        "print(\"MODEL PREDICTION:\\n\", prediction)"
      ],
      "metadata": {
        "id": "Luta907k5av6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tok = all_data[\"test\"].map(preprocess, batched=True, remove_columns=cols, desc=\"Tokenise test\")\n",
        "test_metrics = trainer.evaluate(eval_dataset=test_tok)"
      ],
      "metadata": {
        "id": "gMWqSAN_iPK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_metrics)"
      ],
      "metadata": {
        "id": "Mq29G00NjDhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBPeo-gK0E3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}