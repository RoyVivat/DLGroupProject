# Parameters
clean_diff_text: True
vocab_size: 12000
dim_size: 64
dim_feedforward: 256
num_layers: 2
num_heads: 2
dropout: 0.1
learning_rate: 0.01
weight_decay: 0.001
warmup_steps: null
max_len: 1024
min_summary_length: 64
epochs: 4
batch_size: 64
sample_size: 10000000
grad_accum_steps: 1
label_smoothing: 0.05
beam_size_val: 1
beam_size_sample: 1
length_penalty: 0.6
tokenizer: sentencepiece
